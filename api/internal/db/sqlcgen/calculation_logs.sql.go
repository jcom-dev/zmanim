// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: calculation_logs.sql

package sqlcgen

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const deleteOldCalculationLogs = `-- name: DeleteOldCalculationLogs :exec

DELETE FROM calculation_logs
WHERE created_at < CURRENT_DATE - $1::integer * interval '1 day'
`

// ============================================================================
// MAINTENANCE QUERIES
// ============================================================================
// Deletes calculation logs older than specified days
// Use this to keep the raw logs table manageable
func (q *Queries) DeleteOldCalculationLogs(ctx context.Context, dollar_1 int32) error {
	_, err := q.db.Exec(ctx, deleteOldCalculationLogs, dollar_1)
	return err
}

const getCalculationLogsCount = `-- name: GetCalculationLogsCount :one
SELECT COUNT(*) as total
FROM calculation_logs
`

// Returns total count of calculation logs
func (q *Queries) GetCalculationLogsCount(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getCalculationLogsCount)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getCalculationLogsDiskSize = `-- name: GetCalculationLogsDiskSize :one
SELECT pg_size_pretty(pg_total_relation_size('calculation_logs')) as size
`

// Returns disk size of calculation_logs table
func (q *Queries) GetCalculationLogsDiskSize(ctx context.Context) (string, error) {
	row := q.db.QueryRow(ctx, getCalculationLogsDiskSize)
	var size string
	err := row.Scan(&size)
	return size, err
}

const getLatestRollupDate = `-- name: GetLatestRollupDate :one
SELECT MAX(date) as latest_date
FROM calculation_stats_daily
`

// Returns the latest date that has been rolled up
func (q *Queries) GetLatestRollupDate(ctx context.Context) (interface{}, error) {
	row := q.db.QueryRow(ctx, getLatestRollupDate)
	var latest_date interface{}
	err := row.Scan(&latest_date)
	return latest_date, err
}

const getPlatformMonthlyCalculations = `-- name: GetPlatformMonthlyCalculations :one
SELECT COALESCE(SUM(total_calculations), 0)::bigint as total
FROM calculation_stats_daily
WHERE date >= date_trunc('month', CURRENT_DATE)::date
`

// Returns calculations for current month across all publishers
func (q *Queries) GetPlatformMonthlyCalculations(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getPlatformMonthlyCalculations)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getPlatformStatsDetailed = `-- name: GetPlatformStatsDetailed :one
SELECT
    COALESCE(SUM(total_calculations), 0)::bigint as total_calculations,
    COALESCE(SUM(cache_hits), 0)::bigint as cache_hits,
    COALESCE(SUM(source_web), 0)::bigint as source_web,
    COALESCE(SUM(source_api), 0)::bigint as source_api,
    COALESCE(SUM(source_external), 0)::bigint as source_external,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND((SUM(cache_hits)::numeric / SUM(total_calculations)::numeric) * 100, 2)
        ELSE 0
    END as cache_hit_ratio,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND(SUM(total_response_time_ms)::numeric / SUM(total_calculations)::numeric, 2)
        ELSE 0
    END as avg_response_ms
FROM calculation_stats_daily
`

type GetPlatformStatsDetailedRow struct {
	TotalCalculations int64 `json:"total_calculations"`
	CacheHits         int64 `json:"cache_hits"`
	SourceWeb         int64 `json:"source_web"`
	SourceApi         int64 `json:"source_api"`
	SourceExternal    int64 `json:"source_external"`
	CacheHitRatio     int32 `json:"cache_hit_ratio"`
	AvgResponseMs     int32 `json:"avg_response_ms"`
}

// Returns comprehensive platform-wide stats
func (q *Queries) GetPlatformStatsDetailed(ctx context.Context) (GetPlatformStatsDetailedRow, error) {
	row := q.db.QueryRow(ctx, getPlatformStatsDetailed)
	var i GetPlatformStatsDetailedRow
	err := row.Scan(
		&i.TotalCalculations,
		&i.CacheHits,
		&i.SourceWeb,
		&i.SourceApi,
		&i.SourceExternal,
		&i.CacheHitRatio,
		&i.AvgResponseMs,
	)
	return i, err
}

const getPlatformStatsPerPublisher = `-- name: GetPlatformStatsPerPublisher :many
SELECT
    p.id as publisher_id,
    p.name as publisher_name,
    COALESCE(SUM(csd.total_calculations), 0)::bigint as total_calculations,
    COALESCE(SUM(csd.cache_hits), 0)::bigint as cache_hits,
    CASE
        WHEN SUM(csd.total_calculations) > 0
        THEN ROUND((SUM(csd.cache_hits)::numeric / SUM(csd.total_calculations)::numeric) * 100, 2)
        ELSE 0
    END as cache_hit_ratio
FROM publishers p
LEFT JOIN calculation_stats_daily csd ON csd.publisher_id = p.id
GROUP BY p.id, p.name
HAVING SUM(csd.total_calculations) > 0
ORDER BY total_calculations DESC
LIMIT $1
`

type GetPlatformStatsPerPublisherRow struct {
	PublisherID       int32  `json:"publisher_id"`
	PublisherName     string `json:"publisher_name"`
	TotalCalculations int64  `json:"total_calculations"`
	CacheHits         int64  `json:"cache_hits"`
	CacheHitRatio     int32  `json:"cache_hit_ratio"`
}

// Returns calculation stats grouped by publisher for admin dashboard
func (q *Queries) GetPlatformStatsPerPublisher(ctx context.Context, limit int32) ([]GetPlatformStatsPerPublisherRow, error) {
	rows, err := q.db.Query(ctx, getPlatformStatsPerPublisher, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []GetPlatformStatsPerPublisherRow{}
	for rows.Next() {
		var i GetPlatformStatsPerPublisherRow
		if err := rows.Scan(
			&i.PublisherID,
			&i.PublisherName,
			&i.TotalCalculations,
			&i.CacheHits,
			&i.CacheHitRatio,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getPlatformTotalCalculations = `-- name: GetPlatformTotalCalculations :one

SELECT COALESCE(SUM(total_calculations), 0)::bigint as total
FROM calculation_stats_daily
`

// ============================================================================
// PLATFORM-WIDE STATS (Admin Dashboard)
// ============================================================================
// Returns total calculations across all publishers
func (q *Queries) GetPlatformTotalCalculations(ctx context.Context) (int64, error) {
	row := q.db.QueryRow(ctx, getPlatformTotalCalculations)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getPublisherAvgResponseTime = `-- name: GetPublisherAvgResponseTime :one
SELECT
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND(SUM(total_response_time_ms)::numeric / SUM(total_calculations)::numeric, 2)
        ELSE 0
    END as avg_response_ms
FROM calculation_stats_daily
WHERE publisher_id = $1
`

// Returns average response time for a publisher
func (q *Queries) GetPublisherAvgResponseTime(ctx context.Context, publisherID int32) (int32, error) {
	row := q.db.QueryRow(ctx, getPublisherAvgResponseTime, publisherID)
	var avg_response_ms int32
	err := row.Scan(&avg_response_ms)
	return avg_response_ms, err
}

const getPublisherCacheHitRatio = `-- name: GetPublisherCacheHitRatio :one
SELECT
    COALESCE(SUM(total_calculations), 0)::bigint as total_calculations,
    COALESCE(SUM(cache_hits), 0)::bigint as cache_hits,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND((SUM(cache_hits)::numeric / SUM(total_calculations)::numeric) * 100, 2)
        ELSE 0
    END as cache_hit_ratio
FROM calculation_stats_daily
WHERE publisher_id = $1
`

type GetPublisherCacheHitRatioRow struct {
	TotalCalculations int64 `json:"total_calculations"`
	CacheHits         int64 `json:"cache_hits"`
	CacheHitRatio     int32 `json:"cache_hit_ratio"`
}

// Returns cache hit ratio for a publisher
func (q *Queries) GetPublisherCacheHitRatio(ctx context.Context, publisherID int32) (GetPublisherCacheHitRatioRow, error) {
	row := q.db.QueryRow(ctx, getPublisherCacheHitRatio, publisherID)
	var i GetPublisherCacheHitRatioRow
	err := row.Scan(&i.TotalCalculations, &i.CacheHits, &i.CacheHitRatio)
	return i, err
}

const getPublisherMonthlyCalculations = `-- name: GetPublisherMonthlyCalculations :one
SELECT COALESCE(SUM(total_calculations), 0)::bigint as total
FROM calculation_stats_daily
WHERE publisher_id = $1
  AND date >= date_trunc('month', CURRENT_DATE)::date
`

// Returns calculations for current month from pre-aggregated stats
func (q *Queries) GetPublisherMonthlyCalculations(ctx context.Context, publisherID int32) (int64, error) {
	row := q.db.QueryRow(ctx, getPublisherMonthlyCalculations, publisherID)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const getPublisherMonthlyStatsDetailed = `-- name: GetPublisherMonthlyStatsDetailed :one
SELECT
    COALESCE(SUM(total_calculations), 0)::bigint as total_calculations,
    COALESCE(SUM(cache_hits), 0)::bigint as cache_hits,
    COALESCE(SUM(source_web), 0)::bigint as source_web,
    COALESCE(SUM(source_api), 0)::bigint as source_api,
    COALESCE(SUM(source_external), 0)::bigint as source_external,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND((SUM(cache_hits)::numeric / SUM(total_calculations)::numeric) * 100, 2)
        ELSE 0
    END as cache_hit_ratio,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND(SUM(total_response_time_ms)::numeric / SUM(total_calculations)::numeric, 2)
        ELSE 0
    END as avg_response_ms
FROM calculation_stats_daily
WHERE publisher_id = $1
  AND date >= date_trunc('month', CURRENT_DATE)::date
`

type GetPublisherMonthlyStatsDetailedRow struct {
	TotalCalculations int64 `json:"total_calculations"`
	CacheHits         int64 `json:"cache_hits"`
	SourceWeb         int64 `json:"source_web"`
	SourceApi         int64 `json:"source_api"`
	SourceExternal    int64 `json:"source_external"`
	CacheHitRatio     int32 `json:"cache_hit_ratio"`
	AvgResponseMs     int32 `json:"avg_response_ms"`
}

// Returns stats for current month
func (q *Queries) GetPublisherMonthlyStatsDetailed(ctx context.Context, publisherID int32) (GetPublisherMonthlyStatsDetailedRow, error) {
	row := q.db.QueryRow(ctx, getPublisherMonthlyStatsDetailed, publisherID)
	var i GetPublisherMonthlyStatsDetailedRow
	err := row.Scan(
		&i.TotalCalculations,
		&i.CacheHits,
		&i.SourceWeb,
		&i.SourceApi,
		&i.SourceExternal,
		&i.CacheHitRatio,
		&i.AvgResponseMs,
	)
	return i, err
}

const getPublisherStatsDetailed = `-- name: GetPublisherStatsDetailed :one
SELECT
    COALESCE(SUM(total_calculations), 0)::bigint as total_calculations,
    COALESCE(SUM(cache_hits), 0)::bigint as cache_hits,
    COALESCE(SUM(source_web), 0)::bigint as source_web,
    COALESCE(SUM(source_api), 0)::bigint as source_api,
    COALESCE(SUM(source_external), 0)::bigint as source_external,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND((SUM(cache_hits)::numeric / SUM(total_calculations)::numeric) * 100, 2)
        ELSE 0
    END as cache_hit_ratio,
    CASE
        WHEN SUM(total_calculations) > 0
        THEN ROUND(SUM(total_response_time_ms)::numeric / SUM(total_calculations)::numeric, 2)
        ELSE 0
    END as avg_response_ms
FROM calculation_stats_daily
WHERE publisher_id = $1
`

type GetPublisherStatsDetailedRow struct {
	TotalCalculations int64 `json:"total_calculations"`
	CacheHits         int64 `json:"cache_hits"`
	SourceWeb         int64 `json:"source_web"`
	SourceApi         int64 `json:"source_api"`
	SourceExternal    int64 `json:"source_external"`
	CacheHitRatio     int32 `json:"cache_hit_ratio"`
	AvgResponseMs     int32 `json:"avg_response_ms"`
}

// Returns comprehensive stats for a publisher from pre-aggregated table
func (q *Queries) GetPublisherStatsDetailed(ctx context.Context, publisherID int32) (GetPublisherStatsDetailedRow, error) {
	row := q.db.QueryRow(ctx, getPublisherStatsDetailed, publisherID)
	var i GetPublisherStatsDetailedRow
	err := row.Scan(
		&i.TotalCalculations,
		&i.CacheHits,
		&i.SourceWeb,
		&i.SourceApi,
		&i.SourceExternal,
		&i.CacheHitRatio,
		&i.AvgResponseMs,
	)
	return i, err
}

const getPublisherTotalCalculations = `-- name: GetPublisherTotalCalculations :one


SELECT COALESCE(SUM(total_calculations), 0)::bigint as total
FROM calculation_stats_daily
WHERE publisher_id = $1
`

// Calculation Logging Queries
// Story 8.2: Implement Calculation Logging
//
// Note: Batch inserts are handled via pgx COPY protocol in the service layer
// These queries are for stats aggregation and analytics
// ============================================================================
// STATS AGGREGATION QUERIES (Using Pre-Aggregated Table)
// ============================================================================
// Returns total calculations for a publisher from pre-aggregated stats
func (q *Queries) GetPublisherTotalCalculations(ctx context.Context, publisherID int32) (int64, error) {
	row := q.db.QueryRow(ctx, getPublisherTotalCalculations, publisherID)
	var total int64
	err := row.Scan(&total)
	return total, err
}

const rollupCalculationStatsDaily = `-- name: RollupCalculationStatsDaily :exec

INSERT INTO calculation_stats_daily (
    publisher_id, date, total_calculations, cache_hits,
    total_response_time_ms, source_web, source_api, source_external
)
SELECT
    publisher_id,
    date_calculated,
    COUNT(*)::integer,
    COUNT(*) FILTER (WHERE cache_hit)::integer,
    COALESCE(SUM(response_time_ms), 0)::bigint,
    COUNT(*) FILTER (WHERE source = 1)::integer,
    COUNT(*) FILTER (WHERE source = 2)::integer,
    COUNT(*) FILTER (WHERE source = 3)::integer
FROM calculation_logs
WHERE created_at >= $1::date
  AND created_at < ($1::date + interval '1 day')
GROUP BY publisher_id, date_calculated
ON CONFLICT (publisher_id, date)
DO UPDATE SET
    total_calculations = calculation_stats_daily.total_calculations + EXCLUDED.total_calculations,
    cache_hits = calculation_stats_daily.cache_hits + EXCLUDED.cache_hits,
    total_response_time_ms = calculation_stats_daily.total_response_time_ms + EXCLUDED.total_response_time_ms,
    source_web = calculation_stats_daily.source_web + EXCLUDED.source_web,
    source_api = calculation_stats_daily.source_api + EXCLUDED.source_api,
    source_external = calculation_stats_daily.source_external + EXCLUDED.source_external
`

// ============================================================================
// DAILY ROLLUP QUERIES
// These are used by background jobs to maintain the pre-aggregated table
// ============================================================================
// Aggregates raw logs into daily stats
// Should be run daily via cron/scheduler
func (q *Queries) RollupCalculationStatsDaily(ctx context.Context, dollar_1 pgtype.Date) error {
	_, err := q.db.Exec(ctx, rollupCalculationStatsDaily, dollar_1)
	return err
}
